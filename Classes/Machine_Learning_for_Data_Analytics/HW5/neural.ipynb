{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through the following in this notebook:\n",
    "\n",
    "- Exploring and Processing the Data\n",
    "- Building and Training our Neural Network\n",
    "- Visualizing Loss and Accuracy\n",
    "- Adding Regularization to our Neural Network\n",
    "\n",
    "The code is annotated throughout the notebook and you simply need to download the dataset [here](https://drive.google.com/file/d/1GfvKA0qznNVknghV4botnNxyH-KvODOC/view), put the dataset in the same folder as this notebook and run the code cells below. Note that the results you get might differ slightly as there is a degree of randomness in the way we split our dataset as well as the initialization of our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to read in the CSV file that we've been given. We'll use a package called pandas for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housepricedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14115</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10084</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10382</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6120</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>952</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7420</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11924</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1175</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12968</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10652</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10920</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6120</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11241</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10791</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13695</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7560</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14215</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1158</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7449</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9742</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1777</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4224</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8246</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1060</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14230</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1566</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7200</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11478</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1704</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16321</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6324</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>21930</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>732</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>4928</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>10800</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>656</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>10261</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>936</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>17400</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>8400</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>9000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>12444</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1932</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>7407</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>11584</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>539</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>11526</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>588</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>4426</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>11003</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>8854</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>8500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>8400</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>814</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>26142</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1220</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>11767</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1533</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>9000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>896</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>9262</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>3675</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>17217</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>7500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0        8450            7            5          856         2         1   \n",
       "1        9600            6            8         1262         2         0   \n",
       "2       11250            7            5          920         2         1   \n",
       "3        9550            7            5          756         1         0   \n",
       "4       14260            8            5         1145         2         1   \n",
       "5       14115            5            5          796         1         1   \n",
       "6       10084            8            5         1686         2         0   \n",
       "7       10382            7            6         1107         2         1   \n",
       "8        6120            7            5          952         2         0   \n",
       "9        7420            5            6          991         1         0   \n",
       "10      11200            5            5         1040         1         0   \n",
       "11      11924            9            5         1175         3         0   \n",
       "12      12968            5            6          912         1         0   \n",
       "13      10652            7            5         1494         2         0   \n",
       "14      10920            6            5         1253         1         1   \n",
       "15       6120            7            8          832         1         0   \n",
       "16      11241            6            7         1004         1         0   \n",
       "17      10791            4            5            0         2         0   \n",
       "18      13695            5            5         1114         1         1   \n",
       "19       7560            5            6         1029         1         0   \n",
       "20      14215            8            5         1158         3         1   \n",
       "21       7449            7            7          637         1         0   \n",
       "22       9742            8            5         1777         2         0   \n",
       "23       4224            5            7         1040         1         0   \n",
       "24       8246            5            8         1060         1         0   \n",
       "25      14230            8            5         1566         2         0   \n",
       "26       7200            5            7          900         1         0   \n",
       "27      11478            8            5         1704         2         0   \n",
       "28      16321            5            6         1484         1         0   \n",
       "29       6324            4            6          520         1         0   \n",
       "...       ...          ...          ...          ...       ...       ...   \n",
       "1430    21930            5            5          732         2         1   \n",
       "1431     4928            6            6          958         2         0   \n",
       "1432    10800            4            6          656         2         0   \n",
       "1433    10261            6            5          936         2         1   \n",
       "1434    17400            5            5         1126         2         0   \n",
       "1435     8400            6            9         1319         1         1   \n",
       "1436     9000            4            6          864         1         0   \n",
       "1437    12444            8            5         1932         2         0   \n",
       "1438     7407            6            7          912         1         0   \n",
       "1439    11584            7            6          539         2         1   \n",
       "1440    11526            6            7          588         2         0   \n",
       "1441     4426            6            5          848         1         0   \n",
       "1442    11003           10            5         1017         2         1   \n",
       "1443     8854            6            6          952         1         0   \n",
       "1444     8500            7            5         1422         2         0   \n",
       "1445     8400            6            5          814         1         0   \n",
       "1446    26142            5            7         1188         1         0   \n",
       "1447    10000            8            5         1220         2         1   \n",
       "1448    11767            4            7          560         1         1   \n",
       "1449     1533            5            7          630         1         0   \n",
       "1450     9000            5            5          896         2         2   \n",
       "1451     9262            8            5         1573         2         0   \n",
       "1452     3675            5            5          547         1         0   \n",
       "1453    17217            5            5         1140         1         0   \n",
       "1454     7500            7            5         1221         2         0   \n",
       "1455     7917            6            5          953         2         1   \n",
       "1456    13175            6            6         1542         2         0   \n",
       "1457     9042            7            9         1152         2         0   \n",
       "1458     9717            5            6         1078         1         0   \n",
       "1459     9937            5            6         1256         1         1   \n",
       "\n",
       "      BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0                3             8           0         548                 1  \n",
       "1                3             6           1         460                 1  \n",
       "2                3             6           1         608                 1  \n",
       "3                3             7           1         642                 0  \n",
       "4                4             9           1         836                 1  \n",
       "5                1             5           0         480                 0  \n",
       "6                3             7           1         636                 1  \n",
       "7                3             7           2         484                 1  \n",
       "8                2             8           2         468                 0  \n",
       "9                2             5           2         205                 0  \n",
       "10               3             5           0         384                 0  \n",
       "11               4            11           2         736                 1  \n",
       "12               2             4           0         352                 0  \n",
       "13               3             7           1         840                 1  \n",
       "14               2             5           1         352                 0  \n",
       "15               2             5           0         576                 0  \n",
       "16               2             5           1         480                 0  \n",
       "17               2             6           0         516                 0  \n",
       "18               3             6           0         576                 0  \n",
       "19               3             6           0         294                 0  \n",
       "20               4             9           1         853                 1  \n",
       "21               3             6           1         280                 0  \n",
       "22               3             7           1         534                 1  \n",
       "23               3             6           1         572                 0  \n",
       "24               3             6           1         270                 0  \n",
       "25               3             7           1         890                 1  \n",
       "26               3             5           0         576                 0  \n",
       "27               3             7           1         772                 1  \n",
       "28               2             6           2         319                 1  \n",
       "29               1             4           0         240                 0  \n",
       "...            ...           ...         ...         ...               ...  \n",
       "1430             4             7           1         372                 1  \n",
       "1431             2             5           0         440                 0  \n",
       "1432             4             5           0         216                 0  \n",
       "1433             3             8           1         451                 1  \n",
       "1434             3             5           1         484                 0  \n",
       "1435             3             7           1         462                 1  \n",
       "1436             3             5           0         528                 0  \n",
       "1437             2             7           1         774                 1  \n",
       "1438             2             6           0         923                 0  \n",
       "1439             3             6           1         550                 1  \n",
       "1440             3            11           1         672                 1  \n",
       "1441             1             3           1         420                 0  \n",
       "1442             3            10           1         812                 1  \n",
       "1443             2             4           1         192                 0  \n",
       "1444             3             7           0         626                 1  \n",
       "1445             3             6           0         240                 0  \n",
       "1446             3             6           0         312                 0  \n",
       "1447             3             8           1         556                 1  \n",
       "1448             2             6           0         384                 0  \n",
       "1449             1             3           0           0                 0  \n",
       "1450             4             8           0           0                 0  \n",
       "1451             3             7           1         840                 1  \n",
       "1452             2             5           0         525                 0  \n",
       "1453             3             6           0           0                 0  \n",
       "1454             2             6           0         400                 1  \n",
       "1455             3             7           1         460                 1  \n",
       "1456             3             7           2         500                 1  \n",
       "1457             4             9           2         252                 1  \n",
       "1458             2             5           0         240                 0  \n",
       "1459             3             6           0         276                 0  \n",
       "\n",
       "[1460 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that we have now is in what we call a pandas dataframe. To convert it to an array, simply access its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8450,     7,     5, ...,     0,   548,     1],\n",
       "       [ 9600,     6,     8, ...,     1,   460,     1],\n",
       "       [11250,     7,     5, ...,     1,   608,     1],\n",
       "       ...,\n",
       "       [ 9042,     7,     9, ...,     2,   252,     1],\n",
       "       [ 9717,     5,     6, ...,     0,   240,     0],\n",
       "       [ 9937,     5,     6, ...,     0,   276,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the dataset into our input features and the label we wish to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]\n",
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing our data is very important, as we want the input features to be on the same order of magnitude to make our training easier. We'll use a min-max scaler from scikit-learn which scales our data to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0334198 , 0.66666667, 0.5       , ..., 0.5       , 0.        ,\n",
       "        0.3864598 ],\n",
       "       [0.03879502, 0.55555556, 0.875     , ..., 0.33333333, 0.33333333,\n",
       "        0.32440056],\n",
       "       [0.04650728, 0.66666667, 0.5       , ..., 0.33333333, 0.33333333,\n",
       "        0.42877292],\n",
       "       ...,\n",
       "       [0.03618687, 0.66666667, 1.        , ..., 0.58333333, 0.66666667,\n",
       "        0.17771509],\n",
       "       [0.03934189, 0.44444444, 0.625     , ..., 0.25      , 0.        ,\n",
       "        0.16925247],\n",
       "       [0.04037019, 0.44444444, 0.625     , ..., 0.33333333, 0.        ,\n",
       "        0.19464034]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we wish to set aside some parts of our dataset for a validation set and a test set. We use the function train_test_split from scikit-learn to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training Our First Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Keras to build our architecture. Let's import the code from Keras that we will need to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Sequential model, which means that we merely need to describe the layers above in sequence. Our neural network has three layers:\n",
    "\n",
    "- Hidden layer 1: 32 neurons, ReLU activation\n",
    "- Hidden layer 2: 32 neurons, ReLU activation\n",
    "- Output Layer: 1 neuron, Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our architecture specified, we need to find the best numbers for it. Before we start our training, we have to configure the model by\n",
    "- Telling it what algorithm you want to use to do the optimization (we'll use stochastic gradient descent)\n",
    "- Telling it what loss function to use (for binary classification, we will use binary cross entropy)\n",
    "- Telling it what other metrics you want to track apart from the loss function (we want to track accuracy as well)\n",
    "\n",
    "We do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the data is pretty straightforward and requires us to write one line of code. The function is called 'fit' as we are fitting the parameters to the data. We specify:\n",
    "- what data we are training on, which is X_train and Y_train\n",
    "- the size of our mini-batch \n",
    "- how long we want to train it for (epochs)\n",
    "- what our validation data is so that the model will tell us how we are doing on the validation data at each point.\n",
    "\n",
    "This function will output a history, which we save under the variable hist. We'll use this variable a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 668us/step - loss: 0.6917 - accuracy: 0.5284 - val_loss: 0.6934 - val_accuracy: 0.5479\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 0.6872 - accuracy: 0.6663 - val_loss: 0.6884 - val_accuracy: 0.6210\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 0.6834 - accuracy: 0.6967 - val_loss: 0.6839 - val_accuracy: 0.6712\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.6799 - accuracy: 0.7172 - val_loss: 0.6800 - val_accuracy: 0.7215\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 0.6764 - accuracy: 0.7456 - val_loss: 0.6761 - val_accuracy: 0.7306\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 0.6730 - accuracy: 0.7603 - val_loss: 0.6724 - val_accuracy: 0.7626\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 0.6695 - accuracy: 0.7867 - val_loss: 0.6690 - val_accuracy: 0.7717\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 0.6659 - accuracy: 0.8053 - val_loss: 0.6652 - val_accuracy: 0.7717\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 0.6620 - accuracy: 0.8063 - val_loss: 0.6616 - val_accuracy: 0.7808\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.6579 - accuracy: 0.8239 - val_loss: 0.6573 - val_accuracy: 0.7763\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 0.6532 - accuracy: 0.8278 - val_loss: 0.6528 - val_accuracy: 0.7808\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.6483 - accuracy: 0.8229 - val_loss: 0.6483 - val_accuracy: 0.7854\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 0.6430 - accuracy: 0.8405 - val_loss: 0.6432 - val_accuracy: 0.7808\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.6374 - accuracy: 0.8386 - val_loss: 0.6381 - val_accuracy: 0.7717\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 0.6318 - accuracy: 0.8386 - val_loss: 0.6331 - val_accuracy: 0.7808\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 0.6257 - accuracy: 0.8571 - val_loss: 0.6278 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 0.6197 - accuracy: 0.8581 - val_loss: 0.6221 - val_accuracy: 0.7945\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 0.6134 - accuracy: 0.8581 - val_loss: 0.6165 - val_accuracy: 0.7945\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 0.6069 - accuracy: 0.8620 - val_loss: 0.6104 - val_accuracy: 0.7945\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 0.5999 - accuracy: 0.8659 - val_loss: 0.6033 - val_accuracy: 0.8082\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.5928 - accuracy: 0.8601 - val_loss: 0.5965 - val_accuracy: 0.8128\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 0.5848 - accuracy: 0.8659 - val_loss: 0.5889 - val_accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 0.5765 - accuracy: 0.8669 - val_loss: 0.5812 - val_accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 0.5674 - accuracy: 0.8650 - val_loss: 0.5733 - val_accuracy: 0.8219\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.5581 - accuracy: 0.8699 - val_loss: 0.5644 - val_accuracy: 0.8265\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 0.5484 - accuracy: 0.8669 - val_loss: 0.5551 - val_accuracy: 0.8219\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 0.5388 - accuracy: 0.8669 - val_loss: 0.5456 - val_accuracy: 0.8219\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 0.5282 - accuracy: 0.8679 - val_loss: 0.5363 - val_accuracy: 0.8219\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 0.5179 - accuracy: 0.8708 - val_loss: 0.5270 - val_accuracy: 0.8311\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 0.5075 - accuracy: 0.8679 - val_loss: 0.5170 - val_accuracy: 0.8265\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 0.4968 - accuracy: 0.8738 - val_loss: 0.5067 - val_accuracy: 0.8265\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 0.4865 - accuracy: 0.8718 - val_loss: 0.4976 - val_accuracy: 0.8311\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 0.4760 - accuracy: 0.8738 - val_loss: 0.4881 - val_accuracy: 0.8311\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 0.4658 - accuracy: 0.8718 - val_loss: 0.4793 - val_accuracy: 0.8356\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 0.4560 - accuracy: 0.8796 - val_loss: 0.4704 - val_accuracy: 0.8311\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 0.4464 - accuracy: 0.8728 - val_loss: 0.4610 - val_accuracy: 0.8265\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 0.4366 - accuracy: 0.8728 - val_loss: 0.4545 - val_accuracy: 0.8265\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 0.4277 - accuracy: 0.8816 - val_loss: 0.4446 - val_accuracy: 0.8311\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.4189 - accuracy: 0.8806 - val_loss: 0.4370 - val_accuracy: 0.8356\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 0.4106 - accuracy: 0.8767 - val_loss: 0.4297 - val_accuracy: 0.8311\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 0.4023 - accuracy: 0.8836 - val_loss: 0.4224 - val_accuracy: 0.8311\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 0.3949 - accuracy: 0.8816 - val_loss: 0.4156 - val_accuracy: 0.8311\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 0.3877 - accuracy: 0.8796 - val_loss: 0.4106 - val_accuracy: 0.8402\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 0.3816 - accuracy: 0.8796 - val_loss: 0.4033 - val_accuracy: 0.8447\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 0.3752 - accuracy: 0.8855 - val_loss: 0.3973 - val_accuracy: 0.8402\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 0.3689 - accuracy: 0.8816 - val_loss: 0.3921 - val_accuracy: 0.8447\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 0.3631 - accuracy: 0.8806 - val_loss: 0.3874 - val_accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 0.3582 - accuracy: 0.8806 - val_loss: 0.3823 - val_accuracy: 0.8402\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 0.3533 - accuracy: 0.8826 - val_loss: 0.3783 - val_accuracy: 0.8493\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.3485 - accuracy: 0.8787 - val_loss: 0.3739 - val_accuracy: 0.8493\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 0.3444 - accuracy: 0.8836 - val_loss: 0.3702 - val_accuracy: 0.8493\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 0.3402 - accuracy: 0.8826 - val_loss: 0.3663 - val_accuracy: 0.8447\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 0.3369 - accuracy: 0.8836 - val_loss: 0.3627 - val_accuracy: 0.8447\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 0.3328 - accuracy: 0.8845 - val_loss: 0.3601 - val_accuracy: 0.8539\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 0.3300 - accuracy: 0.8816 - val_loss: 0.3566 - val_accuracy: 0.8447\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 0.3269 - accuracy: 0.8826 - val_loss: 0.3538 - val_accuracy: 0.8539\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 0.3240 - accuracy: 0.8865 - val_loss: 0.3511 - val_accuracy: 0.8493\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 0.3218 - accuracy: 0.8845 - val_loss: 0.3486 - val_accuracy: 0.8493\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 0.3183 - accuracy: 0.8836 - val_loss: 0.3475 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 0.3167 - accuracy: 0.8806 - val_loss: 0.3439 - val_accuracy: 0.8493\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 0.3139 - accuracy: 0.8855 - val_loss: 0.3416 - val_accuracy: 0.8447\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 0.3126 - accuracy: 0.8826 - val_loss: 0.3397 - val_accuracy: 0.8539\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 0.3105 - accuracy: 0.8806 - val_loss: 0.3376 - val_accuracy: 0.8539\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 0.3084 - accuracy: 0.8836 - val_loss: 0.3356 - val_accuracy: 0.8539\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 0.3067 - accuracy: 0.8796 - val_loss: 0.3337 - val_accuracy: 0.8539\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 0.3049 - accuracy: 0.8836 - val_loss: 0.3320 - val_accuracy: 0.8539\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 0.3032 - accuracy: 0.8826 - val_loss: 0.3303 - val_accuracy: 0.8539\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.3019 - accuracy: 0.8826 - val_loss: 0.3290 - val_accuracy: 0.8584\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 0.3008 - accuracy: 0.8836 - val_loss: 0.3272 - val_accuracy: 0.8539\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 0.2993 - accuracy: 0.8836 - val_loss: 0.3257 - val_accuracy: 0.8539\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 0.2975 - accuracy: 0.8836 - val_loss: 0.3242 - val_accuracy: 0.8539\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 0.2963 - accuracy: 0.8855 - val_loss: 0.3238 - val_accuracy: 0.8539\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 0.2956 - accuracy: 0.8855 - val_loss: 0.3214 - val_accuracy: 0.8539\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2943 - accuracy: 0.8816 - val_loss: 0.3201 - val_accuracy: 0.8584\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2935 - accuracy: 0.8845 - val_loss: 0.3189 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 0.2926 - accuracy: 0.8816 - val_loss: 0.3177 - val_accuracy: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.2907 - accuracy: 0.8845 - val_loss: 0.3175 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 0.2909 - accuracy: 0.8845 - val_loss: 0.3157 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 0.2896 - accuracy: 0.8875 - val_loss: 0.3142 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 0.2883 - accuracy: 0.8845 - val_loss: 0.3132 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 0.2876 - accuracy: 0.8845 - val_loss: 0.3128 - val_accuracy: 0.8721\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 0.2873 - accuracy: 0.8845 - val_loss: 0.3121 - val_accuracy: 0.8584\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2865 - accuracy: 0.8865 - val_loss: 0.3098 - val_accuracy: 0.8676\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 0.2856 - accuracy: 0.8865 - val_loss: 0.3087 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 0.2846 - accuracy: 0.8865 - val_loss: 0.3083 - val_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 0.2843 - accuracy: 0.8845 - val_loss: 0.3069 - val_accuracy: 0.8767\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 0.2828 - accuracy: 0.8845 - val_loss: 0.3065 - val_accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 0.2829 - accuracy: 0.8894 - val_loss: 0.3046 - val_accuracy: 0.8721\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 0.2819 - accuracy: 0.8845 - val_loss: 0.3039 - val_accuracy: 0.8813\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 0.2816 - accuracy: 0.8865 - val_loss: 0.3029 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 0.2807 - accuracy: 0.8865 - val_loss: 0.3018 - val_accuracy: 0.8767\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 0.2804 - accuracy: 0.8855 - val_loss: 0.3010 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2795 - accuracy: 0.8894 - val_loss: 0.3007 - val_accuracy: 0.8858\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2798 - accuracy: 0.8885 - val_loss: 0.2996 - val_accuracy: 0.8858\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2780 - accuracy: 0.8894 - val_loss: 0.2990 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 0.2774 - accuracy: 0.8875 - val_loss: 0.2985 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 0.2772 - accuracy: 0.8865 - val_loss: 0.2965 - val_accuracy: 0.8767\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 0.2771 - accuracy: 0.8885 - val_loss: 0.2957 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 0.2759 - accuracy: 0.8885 - val_loss: 0.2948 - val_accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 0.2756 - accuracy: 0.8904 - val_loss: 0.2952 - val_accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our data on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8812785148620605"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss andÂ Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relevant package we need to do the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualize the training loss and the validation loss like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the training accuracy and the validation accuracy like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization to our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train a model which will overfit, which we call Model 2. This might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.7935 - val_loss: 0.3441 - val_accuracy: 0.8813\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8620 - val_loss: 0.3011 - val_accuracy: 0.8950\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2861 - accuracy: 0.8865 - val_loss: 0.2853 - val_accuracy: 0.8995\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2645 - accuracy: 0.8875 - val_loss: 0.2909 - val_accuracy: 0.8995\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2691 - accuracy: 0.8865 - val_loss: 0.2746 - val_accuracy: 0.9132\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2582 - accuracy: 0.8875 - val_loss: 0.2779 - val_accuracy: 0.8904\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.8963 - val_loss: 0.3225 - val_accuracy: 0.8995\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2609 - accuracy: 0.8953 - val_loss: 0.3199 - val_accuracy: 0.8995\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.2625 - accuracy: 0.8914 - val_loss: 0.3346 - val_accuracy: 0.8813\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2379 - accuracy: 0.8992 - val_loss: 0.2975 - val_accuracy: 0.9224\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2108 - accuracy: 0.9129 - val_loss: 0.3564 - val_accuracy: 0.8904\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2244 - accuracy: 0.9041 - val_loss: 0.3076 - val_accuracy: 0.9132\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2089 - accuracy: 0.9129 - val_loss: 0.3111 - val_accuracy: 0.9087\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.2295 - accuracy: 0.9051 - val_loss: 0.3431 - val_accuracy: 0.8858\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2196 - accuracy: 0.9100 - val_loss: 0.3193 - val_accuracy: 0.9178\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2014 - accuracy: 0.9139 - val_loss: 0.3347 - val_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9139 - val_loss: 0.3122 - val_accuracy: 0.9041\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1954 - accuracy: 0.9227 - val_loss: 0.3784 - val_accuracy: 0.9132\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2022 - accuracy: 0.9178 - val_loss: 0.3728 - val_accuracy: 0.9041\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2051 - accuracy: 0.9110 - val_loss: 0.3348 - val_accuracy: 0.9178\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1907 - accuracy: 0.9178 - val_loss: 0.3208 - val_accuracy: 0.8995\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1949 - accuracy: 0.9188 - val_loss: 0.3714 - val_accuracy: 0.9132\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9129 - val_loss: 0.3724 - val_accuracy: 0.9315\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1922 - accuracy: 0.9178 - val_loss: 0.3652 - val_accuracy: 0.9178\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2031 - accuracy: 0.9149 - val_loss: 0.3623 - val_accuracy: 0.9132\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.2112 - accuracy: 0.9159 - val_loss: 0.3977 - val_accuracy: 0.9041\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1929 - accuracy: 0.9227 - val_loss: 0.3385 - val_accuracy: 0.9269\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1847 - accuracy: 0.9266 - val_loss: 0.3922 - val_accuracy: 0.8721\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.2444 - accuracy: 0.8992 - val_loss: 0.3094 - val_accuracy: 0.9087\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1989 - accuracy: 0.9149 - val_loss: 0.3413 - val_accuracy: 0.9315\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9168 - val_loss: 0.3540 - val_accuracy: 0.9315\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.2047 - accuracy: 0.9149 - val_loss: 0.3724 - val_accuracy: 0.9178\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1761 - accuracy: 0.9286 - val_loss: 0.3745 - val_accuracy: 0.9178\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1742 - accuracy: 0.9217 - val_loss: 0.3880 - val_accuracy: 0.9087\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1873 - accuracy: 0.9178 - val_loss: 0.4179 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1946 - accuracy: 0.9227 - val_loss: 0.3662 - val_accuracy: 0.9132\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1782 - accuracy: 0.9247 - val_loss: 0.3489 - val_accuracy: 0.9315\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1719 - accuracy: 0.9295 - val_loss: 0.4298 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1800 - accuracy: 0.9276 - val_loss: 0.3808 - val_accuracy: 0.9315\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1737 - accuracy: 0.9286 - val_loss: 0.3963 - val_accuracy: 0.9269\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1721 - accuracy: 0.9315 - val_loss: 0.4052 - val_accuracy: 0.9132\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1750 - accuracy: 0.9256 - val_loss: 0.4809 - val_accuracy: 0.8904\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1830 - accuracy: 0.9266 - val_loss: 0.4024 - val_accuracy: 0.9224\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1773 - accuracy: 0.9247 - val_loss: 0.3879 - val_accuracy: 0.9224\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1605 - accuracy: 0.9364 - val_loss: 0.4599 - val_accuracy: 0.9178\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2006 - accuracy: 0.9168 - val_loss: 0.3832 - val_accuracy: 0.9178\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1739 - accuracy: 0.9286 - val_loss: 0.4115 - val_accuracy: 0.9315\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1636 - accuracy: 0.9325 - val_loss: 0.4155 - val_accuracy: 0.9178\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1767 - accuracy: 0.9305 - val_loss: 0.4500 - val_accuracy: 0.9087\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9286 - val_loss: 0.3866 - val_accuracy: 0.9315\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1568 - accuracy: 0.9384 - val_loss: 0.4136 - val_accuracy: 0.9224\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 928s 908ms/step - loss: 0.1451 - accuracy: 0.9403 - val_loss: 0.4508 - val_accuracy: 0.9132\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1494 - accuracy: 0.9393 - val_loss: 0.5152 - val_accuracy: 0.9178\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1615 - accuracy: 0.9286 - val_loss: 0.5033 - val_accuracy: 0.9132\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1705 - accuracy: 0.9315 - val_loss: 0.5747 - val_accuracy: 0.8995\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1706 - accuracy: 0.9335 - val_loss: 0.5047 - val_accuracy: 0.9224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1951 - accuracy: 0.9168 - val_loss: 0.4283 - val_accuracy: 0.9132\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1729 - accuracy: 0.9227 - val_loss: 0.4604 - val_accuracy: 0.9132\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1843 - accuracy: 0.9227 - val_loss: 0.4414 - val_accuracy: 0.8950\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1869 - accuracy: 0.9198 - val_loss: 0.4115 - val_accuracy: 0.9132\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 11s 11ms/step - loss: 0.1763 - accuracy: 0.9256 - val_loss: 0.4194 - val_accuracy: 0.9224\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 2131s 2s/step - loss: 0.1536 - accuracy: 0.9266 - val_loss: 0.4212 - val_accuracy: 0.9224\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1494 - accuracy: 0.9403 - val_loss: 0.4352 - val_accuracy: 0.9269\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1476 - accuracy: 0.9364 - val_loss: 0.8045 - val_accuracy: 0.8493\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.2055 - accuracy: 0.9237 - val_loss: 0.4400 - val_accuracy: 0.9361\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.9256 - val_loss: 0.4167 - val_accuracy: 0.9132\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9305 - val_loss: 0.5022 - val_accuracy: 0.8995\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1562 - accuracy: 0.9256 - val_loss: 0.4162 - val_accuracy: 0.9361\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1521 - accuracy: 0.9413 - val_loss: 0.4083 - val_accuracy: 0.9315\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 6s 6ms/step - loss: 0.1362 - accuracy: 0.9384 - val_loss: 0.4434 - val_accuracy: 0.9269\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 3231s 3s/step - loss: 0.1347 - accuracy: 0.9413 - val_loss: 0.5120 - val_accuracy: 0.8950\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1629 - accuracy: 0.9315 - val_loss: 0.4641 - val_accuracy: 0.9269\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1550 - accuracy: 0.9413 - val_loss: 0.4620 - val_accuracy: 0.8995\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.9472 - val_loss: 0.4932 - val_accuracy: 0.9224\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9442 - val_loss: 0.5673 - val_accuracy: 0.9041\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.9452 - val_loss: 0.5607 - val_accuracy: 0.8813\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1839 - accuracy: 0.9237 - val_loss: 0.4221 - val_accuracy: 0.8995\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9295 - val_loss: 0.5014 - val_accuracy: 0.9224\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 1677s 2s/step - loss: 0.1302 - accuracy: 0.9472 - val_loss: 0.5982 - val_accuracy: 0.9178\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1271 - accuracy: 0.9569 - val_loss: 0.6774 - val_accuracy: 0.8858\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1552 - accuracy: 0.9335 - val_loss: 0.6196 - val_accuracy: 0.8995\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1245 - accuracy: 0.9521 - val_loss: 0.4360 - val_accuracy: 0.8995\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1382 - accuracy: 0.9344 - val_loss: 0.6458 - val_accuracy: 0.9315\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1413 - accuracy: 0.9374 - val_loss: 0.7324 - val_accuracy: 0.9315\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 2s 1ms/step - loss: 0.1511 - accuracy: 0.9384 - val_loss: 0.5980 - val_accuracy: 0.9178\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 598s 585ms/step - loss: 0.1346 - accuracy: 0.9442 - val_loss: 0.5930 - val_accuracy: 0.9178\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1370 - accuracy: 0.9481 - val_loss: 0.5958 - val_accuracy: 0.9269\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9521 - val_loss: 0.6357 - val_accuracy: 0.8950\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1211 - accuracy: 0.9501 - val_loss: 0.5928 - val_accuracy: 0.9132\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1407 - accuracy: 0.9452 - val_loss: 0.5116 - val_accuracy: 0.8858\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1764 - accuracy: 0.9325 - val_loss: 0.5547 - val_accuracy: 0.8995\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 1s 1ms/step - loss: 0.1592 - accuracy: 0.9315 - val_loss: 0.3914 - val_accuracy: 0.9041\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 2s 2ms/step - loss: 0.1430 - accuracy: 0.9384 - val_loss: 0.4708 - val_accuracy: 0.9315\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 17s 17ms/step - loss: 0.1221 - accuracy: 0.9521 - val_loss: 0.5655 - val_accuracy: 0.9041\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 20s 19ms/step - loss: 0.1347 - accuracy: 0.9403 - val_loss: 0.5750 - val_accuracy: 0.9087\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 20s 20ms/step - loss: 0.1340 - accuracy: 0.9364 - val_loss: 0.5382 - val_accuracy: 0.9269\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 7s 7ms/step - loss: 0.1627 - accuracy: 0.9384 - val_loss: 0.4431 - val_accuracy: 0.9269\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 5s 5ms/step - loss: 0.1360 - accuracy: 0.9481 - val_loss: 0.5524 - val_accuracy: 0.8858\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 4s 4ms/step - loss: 0.1400 - accuracy: 0.9423 - val_loss: 0.6695 - val_accuracy: 0.9178\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 4s 4ms/step - loss: 0.1392 - accuracy: 0.9481 - val_loss: 0.4211 - val_accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(1000, activation='relu', input_shape=(10,)),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist_2 = model_2.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same visualization to see what overfitting looks like in terms of the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_2.history['loss'])\n",
    "plt.plot(hist_2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the overfitting we see in Model 2, we'll incorporate L2 regularization and dropout in our third model here (Model 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(10,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 4s 4ms/step - loss: 14.3553 - acc: 0.6644 - val_loss: 3.9405 - val_acc: 0.7032\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 1.6741 - acc: 0.8346 - val_loss: 0.6663 - val_acc: 0.8356\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.5775 - acc: 0.8650 - val_loss: 0.5372 - val_acc: 0.8447\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.5513 - acc: 0.8444 - val_loss: 0.5168 - val_acc: 0.8584\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.5378 - acc: 0.8532 - val_loss: 0.5817 - val_acc: 0.8539\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.5064 - acc: 0.8738 - val_loss: 0.4867 - val_acc: 0.8447\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4793 - acc: 0.8728 - val_loss: 0.4744 - val_acc: 0.8584\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4655 - acc: 0.8816 - val_loss: 0.4695 - val_acc: 0.8584\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4767 - acc: 0.8767 - val_loss: 0.4726 - val_acc: 0.8584\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4598 - acc: 0.8836 - val_loss: 0.5118 - val_acc: 0.8493\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4627 - acc: 0.8796 - val_loss: 0.5189 - val_acc: 0.8630\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4666 - acc: 0.8748 - val_loss: 0.4534 - val_acc: 0.8493\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4617 - acc: 0.8777 - val_loss: 0.4631 - val_acc: 0.8584\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4364 - acc: 0.8973 - val_loss: 0.4756 - val_acc: 0.8630\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4694 - acc: 0.8718 - val_loss: 0.5175 - val_acc: 0.8676\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4643 - acc: 0.8699 - val_loss: 0.4750 - val_acc: 0.8676\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4367 - acc: 0.8933 - val_loss: 0.4557 - val_acc: 0.8676\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4568 - acc: 0.8875 - val_loss: 0.4655 - val_acc: 0.8539\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4388 - acc: 0.8943 - val_loss: 0.4581 - val_acc: 0.8676\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4472 - acc: 0.8826 - val_loss: 0.4494 - val_acc: 0.8493\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4453 - acc: 0.8875 - val_loss: 0.4648 - val_acc: 0.8630\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4410 - acc: 0.8885 - val_loss: 0.4531 - val_acc: 0.8539\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4556 - acc: 0.8787 - val_loss: 0.4687 - val_acc: 0.8676\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4589 - acc: 0.8699 - val_loss: 0.4696 - val_acc: 0.8630\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4506 - acc: 0.8777 - val_loss: 0.4528 - val_acc: 0.8630\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4449 - acc: 0.8806 - val_loss: 0.4466 - val_acc: 0.8539\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4399 - acc: 0.8875 - val_loss: 0.4669 - val_acc: 0.8676\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4627 - acc: 0.8845 - val_loss: 0.4547 - val_acc: 0.8539\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4501 - acc: 0.8885 - val_loss: 0.4531 - val_acc: 0.8584\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4455 - acc: 0.8796 - val_loss: 0.4494 - val_acc: 0.8447\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4542 - acc: 0.8796 - val_loss: 0.4631 - val_acc: 0.8630\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4598 - acc: 0.8767 - val_loss: 0.4590 - val_acc: 0.8584\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4436 - acc: 0.8767 - val_loss: 0.4553 - val_acc: 0.8539\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4390 - acc: 0.8826 - val_loss: 0.4442 - val_acc: 0.8539\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4440 - acc: 0.8845 - val_loss: 0.4566 - val_acc: 0.8676\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4416 - acc: 0.8914 - val_loss: 0.4531 - val_acc: 0.8676\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4422 - acc: 0.8816 - val_loss: 0.4723 - val_acc: 0.8721\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4459 - acc: 0.8875 - val_loss: 0.4515 - val_acc: 0.8584\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4594 - acc: 0.8708 - val_loss: 0.4521 - val_acc: 0.8493\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4438 - acc: 0.8767 - val_loss: 0.4591 - val_acc: 0.8584\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4361 - acc: 0.8885 - val_loss: 0.4464 - val_acc: 0.8447\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4494 - acc: 0.8708 - val_loss: 0.4539 - val_acc: 0.8676\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4392 - acc: 0.8836 - val_loss: 0.4517 - val_acc: 0.8584\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4392 - acc: 0.8767 - val_loss: 0.4432 - val_acc: 0.8630\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4292 - acc: 0.8924 - val_loss: 0.4568 - val_acc: 0.8630\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4360 - acc: 0.8855 - val_loss: 0.4503 - val_acc: 0.8630\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4309 - acc: 0.8865 - val_loss: 0.4435 - val_acc: 0.8630\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4583 - acc: 0.8659 - val_loss: 0.4487 - val_acc: 0.8584\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4417 - acc: 0.8904 - val_loss: 0.4489 - val_acc: 0.8630\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4344 - acc: 0.8855 - val_loss: 0.4693 - val_acc: 0.8676\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4428 - acc: 0.8865 - val_loss: 0.4479 - val_acc: 0.8676\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4470 - acc: 0.8708 - val_loss: 0.4669 - val_acc: 0.8584\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4324 - acc: 0.8933 - val_loss: 0.4504 - val_acc: 0.8630\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4427 - acc: 0.8826 - val_loss: 0.4517 - val_acc: 0.8630\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4477 - acc: 0.8816 - val_loss: 0.4645 - val_acc: 0.8539\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4362 - acc: 0.8787 - val_loss: 0.4494 - val_acc: 0.8584\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4453 - acc: 0.8826 - val_loss: 0.4723 - val_acc: 0.8721\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4561 - acc: 0.8806 - val_loss: 0.4537 - val_acc: 0.8584\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4252 - acc: 0.8865 - val_loss: 0.4566 - val_acc: 0.8630\n",
      "Epoch 60/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4324 - acc: 0.8865 - val_loss: 0.4518 - val_acc: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4310 - acc: 0.8855 - val_loss: 0.4458 - val_acc: 0.8584\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4380 - acc: 0.8855 - val_loss: 0.4518 - val_acc: 0.8676\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4400 - acc: 0.8845 - val_loss: 0.4542 - val_acc: 0.8630\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4267 - acc: 0.8953 - val_loss: 0.4671 - val_acc: 0.8539\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4308 - acc: 0.8924 - val_loss: 0.4597 - val_acc: 0.8630\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4338 - acc: 0.8904 - val_loss: 0.4571 - val_acc: 0.8584\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4284 - acc: 0.8845 - val_loss: 0.5106 - val_acc: 0.8539\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4338 - acc: 0.8826 - val_loss: 0.4462 - val_acc: 0.8630\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4381 - acc: 0.8924 - val_loss: 0.4434 - val_acc: 0.8630\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4268 - acc: 0.8865 - val_loss: 0.4527 - val_acc: 0.8630\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4298 - acc: 0.8836 - val_loss: 0.4551 - val_acc: 0.8584\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4450 - acc: 0.8816 - val_loss: 0.4745 - val_acc: 0.8630\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4387 - acc: 0.8748 - val_loss: 0.4447 - val_acc: 0.8539\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4368 - acc: 0.8904 - val_loss: 0.5046 - val_acc: 0.8630\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4409 - acc: 0.8787 - val_loss: 0.4390 - val_acc: 0.8676\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4421 - acc: 0.8787 - val_loss: 0.4402 - val_acc: 0.8676\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4663 - acc: 0.8640 - val_loss: 0.4643 - val_acc: 0.8721\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4804 - acc: 0.8601 - val_loss: 0.4621 - val_acc: 0.8676\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4374 - acc: 0.8826 - val_loss: 0.4562 - val_acc: 0.8584\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4366 - acc: 0.8855 - val_loss: 0.4460 - val_acc: 0.8539\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4338 - acc: 0.8816 - val_loss: 0.4493 - val_acc: 0.8584\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4356 - acc: 0.8845 - val_loss: 0.4400 - val_acc: 0.8630\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4470 - acc: 0.8767 - val_loss: 0.5096 - val_acc: 0.8539\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4557 - acc: 0.8679 - val_loss: 0.4532 - val_acc: 0.8630\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4333 - acc: 0.8953 - val_loss: 0.4512 - val_acc: 0.8676\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4645 - acc: 0.8689 - val_loss: 0.4689 - val_acc: 0.8721\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4494 - acc: 0.8767 - val_loss: 0.4476 - val_acc: 0.8630\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4445 - acc: 0.8787 - val_loss: 0.4514 - val_acc: 0.8584\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4268 - acc: 0.8865 - val_loss: 0.4540 - val_acc: 0.8493\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4349 - acc: 0.8894 - val_loss: 0.4579 - val_acc: 0.8584\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4309 - acc: 0.8757 - val_loss: 0.4457 - val_acc: 0.8584\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4321 - acc: 0.8836 - val_loss: 0.4537 - val_acc: 0.8630\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4233 - acc: 0.8865 - val_loss: 0.4550 - val_acc: 0.8630\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4485 - acc: 0.8738 - val_loss: 0.4468 - val_acc: 0.8584\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4415 - acc: 0.8855 - val_loss: 0.4457 - val_acc: 0.8630\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4521 - acc: 0.8777 - val_loss: 0.4718 - val_acc: 0.8721\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4238 - acc: 0.8885 - val_loss: 0.4501 - val_acc: 0.8676\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4459 - acc: 0.8836 - val_loss: 0.4451 - val_acc: 0.8630\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4271 - acc: 0.8894 - val_loss: 0.4492 - val_acc: 0.8630\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 3s 3ms/step - loss: 0.4193 - acc: 0.8875 - val_loss: 0.4464 - val_acc: 0.8584\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist_3 = model_3.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now plot the loss and accuracy graphs for Model 3. You'll notice that the loss is a lot higher at the start, and that's because we've changed our loss function. To plot such that the window is zoomed in between 0 and 1.2 for the loss, we add an additional line of code (plt.ylim) when plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_3.history['loss'])\n",
    "plt.plot(hist_3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.ylim(top=1.2, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared to Model 2, you should see that there's less overfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
